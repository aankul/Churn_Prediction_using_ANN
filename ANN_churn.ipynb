{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1 : Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify inputs and output\n",
    "X = dataset.iloc[:,3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical variables into numerical values\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "#Encode the country name\n",
    "#Instantiate\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "#Convert\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encode gender\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create dummy variables for country variables as it contains 3 categories\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove one of the dummy variable as it will be implicit\n",
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 : ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "#To initialize ANN\n",
    "from keras.models import Sequential\n",
    "#To build layers in ANN\n",
    "from keras.layers import Dense\n",
    "#To prevent over-fitting, we use dropout - At each iteration, some of the neurons r randomly disabled to prevent them from \n",
    "#Being too dependent on each other\n",
    "#U can choose which layer to apply\n",
    "from Keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amuly\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\", input_dim=11)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#Add the input layer and first hidden layer\n",
    "#Rule of thumb : Number of hidden layer = (no of input layer + output layer )/2\n",
    "classifier.add(Dense(input_dim=11,output_dim = 6, init = 'uniform', activation='relu'))\n",
    "#Try different values of p and check for overfitting, shoulb be between 1 and 4\n",
    "classifier.add(Dropout(p=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amuly\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#Add the second hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation='relu'))\n",
    "classifier.add(Dropout(p=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amuly\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#Add the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compiling the ANN\n",
    "#Read about metrics\n",
    "classifier.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 580/8000 [=>............................] - ETA: 2s - loss: 0.4263 - acc: 0.8086"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amuly\\Anaconda3\\lib\\site-packages\\keras\\models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s - loss: 0.4017 - acc: 0.8346     \n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1s - loss: 0.4020 - acc: 0.8349     \n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1s - loss: 0.4020 - acc: 0.8349     \n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1s - loss: 0.4016 - acc: 0.8342     \n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 2s - loss: 0.4016 - acc: 0.8355     \n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1s - loss: 0.4016 - acc: 0.8337     \n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1s - loss: 0.4015 - acc: 0.8340     \n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1s - loss: 0.4013 - acc: 0.8339     \n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 2s - loss: 0.4017 - acc: 0.8352     \n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1s - loss: 0.4015 - acc: 0.8354     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x213b0d3ac50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting model to training set\n",
    "#Batch size for batch stocastic gradient decent\n",
    "classifier.fit(X_train,y_train,batch_size=10,nb_epoch=10)\n",
    "#The accuracy value should converge after some epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 : Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict the output, since its a sigmoid, we have to define a treshold for binary classification\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#To set the threshold\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1548,   47],\n",
       "       [ 270,  135]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84150000000000003"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the accuracy!\n",
    "accuracy = (cm[0,0] + cm[1,1])/2000\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict a new output\n",
    "#Use the same scale and encoding\n",
    "new_prediction = classifier.predict(sc.transform(np.array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False]], dtype=bool)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the op\n",
    "(new_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 : Evaluate and Improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras wrapper for sklearn\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KerasClassifier has an input which is a function\n",
    "def build_classifier() :\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(input_dim=11,output_dim = 6, init = 'uniform', activation='relu'))\n",
    "    classifier.add(Dense(output_dim = 6, init = 'uniform', activation='relu'))\n",
    "    classifier.add(Dense(output_dim = 1, init = 'uniform', activation='sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#New Classifier trained with cross validation\n",
    "classifier = KerasClassifier(build_fn=build_classifier,batch_size=10,nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cross Validation\n",
    "#For parallel computation -> n_jobs=-1\n",
    "accuracies = cross_val_score(estimator=classifier,X=X_train,y=y_train,cv=5,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CHeck for low bias and Variance\n",
    "mean = accuracies.mean()\n",
    "var = accuracies.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 : Improve ANN / Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Added DROPOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyper-parameters :- no of epochs, batch size, optimizer, no of nuerons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GridSearch for selecting parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def build_classifier(optimizer) :\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(input_dim=11,output_dim = 6, init = 'uniform', activation='relu'))\n",
    "    classifier.add(Dense(output_dim = 6, init = 'uniform', activation='relu'))\n",
    "    classifier.add(Dense(output_dim = 1, init = 'uniform', activation='sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer,loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn=build_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'batch_size' : [25,32],\n",
    "             'nb_epoch' : [100,500],\n",
    "             'optimizer' : ['adam','rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search = GrisSearchCV(estimator = classifier, param_grid = parameters,\n",
    "                          scoring = 'accuracy', cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
